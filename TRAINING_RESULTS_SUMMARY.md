# 模型训练结果总结

## 训练概况

- **训练日期**: 2025-12-04
- **数据集**: 自建数据集（55个视频，25种和弦）
- **训练轮数**: 30个epoch
- **模型版本**: AMT
- **最佳Epoch**: 第26个epoch（根据验证损失）

## 训练配置

根据 `saved_models/AMT/model_params.txt`：

- **模型架构**: Video Music Transformer
- **RPR**: True（相对位置编码）
- **层数**: 6层
- **注意力头数**: 8
- **模型维度**: 512
- **前馈网络维度**: 1024
- **Dropout**: 0.1
- **批次大小**: 1
- **最大序列长度**:
  - MIDI: 2048
  - Video: 300
  - Chord: 300
- **视觉模型**: CLIP ViT-L/14@336px
- **情感模型**: 6类情感（6c_l14p）

## 训练结果

### 第30个Epoch（最终）

| 指标 | 训练集 | 验证集 |
|------|--------|--------|
| **总损失** | 1.0415 | 1.0915 |
| **和弦损失** | 1.6236 | 1.7957 |
| **情感损失** | 0.6534 | 0.6221 |
| **学习率** | 0.000220 | - |

### 最佳Epoch（第26个epoch）

根据 `best_epochs.txt`，最佳验证损失出现在第26个epoch：

- **验证总损失**: 1.0819
- **验证和弦损失**: 1.7524
- **验证情感损失**: 0.6349

### 训练趋势（最后5个epoch）

| Epoch | 训练总损失 | 验证总损失 | 训练和弦损失 | 验证和弦损失 |
|-------|-----------|-----------|-------------|-------------|
| 26 | 1.0371 | **1.0819** | 1.6272 | 1.7524 |
| 27 | 0.9999 | 1.0987 | 1.5196 | 1.7875 |
| 28 | 1.0386 | 1.1352 | 1.6119 | 1.8612 |
| 29 | 1.0506 | 1.1665 | 1.6481 | 1.9533 |
| 30 | 1.0415 | 1.0915 | 1.6236 | 1.7957 |

### 训练分析

1. **损失趋势**:
   - 训练损失在第27个epoch达到最低（0.9999）
   - 验证损失在第26个epoch达到最低（1.0819）
   - 第28-29个epoch出现轻微过拟合（验证损失上升）
   - 第30个epoch验证损失有所恢复（1.0915）

2. **和弦识别性能**:
   - 训练集和弦损失：1.6236（第30个epoch）
   - 验证集和弦损失：1.7957（第30个epoch）
   - 最佳验证和弦损失：1.7524（第26个epoch）

3. **情感识别性能**:
   - 训练集情感损失：0.6534（第30个epoch）
   - 验证集情感损失：0.6221（第30个epoch）
   - 验证集情感损失略低于训练集，说明情感识别泛化良好

## 模型文件

### 权重文件

- **最佳模型**: `saved_models/AMT/best_loss_weights.pickle` (125MB)
  - 来自第26个epoch
  - 验证损失最低：1.0819

- **最终模型**: `saved_models/AMT/weights/epoch_0030.pickle` (125MB)
  - 第30个epoch的权重

- **所有epoch权重**: `saved_models/AMT/weights/epoch_0000.pickle` 到 `epoch_0030.pickle`
  - 共31个文件（0-30个epoch）
  - 每个文件约125MB

### 其他文件

- `best_epochs.txt`: 记录最佳epoch信息
- `results.csv`: 详细的训练日志（81行，包含所有epoch的损失）
- `model_params.txt`: 模型配置参数

## 生成结果

已成功生成以下视频的音乐：

### 1. 视频 015（测试集）

- **输出文件**:
  - MIDI: `output_vevo/AMT/015/015_cgen_rd.mid` (7.2KB)
  - 音频: `output_vevo/AMT/015/015_cgen_rd.flac` (13MB)
  - 视频: `output_vevo/AMT/015/015_cgen_rd.mp4` (18MB)
  - 标注: `output_vevo/AMT/015/015_cgen_rd.lab` (2.1KB)

### 2. 视频 049（训练集）

- **输出文件**:
  - MIDI: `output_vevo/AMT/049/049_cgen_rd.mid` (16KB)
  - 音频: `output_vevo/AMT/049/049_cgen_rd.flac` (16MB)
  - 视频: `output_vevo/AMT/049/049_cgen_rd.mp4` (12MB)
  - 标注: `output_vevo/AMT/049/049_cgen_rd.lab` (2.1KB)

## 训练特点

### 优点

1. **训练稳定**: 损失曲线整体平稳，没有出现剧烈波动
2. **情感识别良好**: 验证集情感损失（0.6221）低于训练集（0.6534），说明泛化能力强
3. **模型收敛**: 30个epoch后，损失趋于稳定

### 需要改进的地方

1. **和弦识别**: 验证集和弦损失（1.7957）高于训练集（1.6236），存在一定过拟合
2. **损失值**: 整体损失值仍然较高，可能需要更多训练或调整超参数
3. **数据集规模**: 55个视频可能不足以充分训练模型，建议扩大数据集

## 建议

1. **继续训练**: 可以考虑继续训练更多epoch，观察损失是否进一步下降
2. **调整超参数**: 
   - 尝试不同的学习率
   - 调整dropout率
   - 尝试不同的模型架构参数
3. **扩大数据集**: 收集更多视频数据，提高模型泛化能力
4. **数据增强**: 考虑使用数据增强技术
5. **早停策略**: 可以设置早停机制，在验证损失不再下降时停止训练

## 下一步工作

1. ✅ 模型训练完成（30个epoch）
2. ✅ 生成测试结果（015, 049）
3. ⏳ 评估生成质量（人工评估或自动评估指标）
4. ⏳ 对比不同epoch的生成效果
5. ⏳ 在更多视频上测试模型

---

**报告生成时间**: 2025-12-04  
**模型版本**: AMT  
**数据集版本**: v1（25种和弦）

